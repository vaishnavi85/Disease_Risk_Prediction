# -*- coding: utf-8 -*-
"""Disease_Risk _Prediction_Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XEO63jguM32_wdWBe2k6knJrPuzes6vY
"""

pip install pandas numpy scikit-learn xgboost shap matplotlib seaborn plotly

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score
from sklearn.linear_model import LogisticRegression
import xgboost as xgb
import shap
import plotly.express as px

# Load patient data
data = pd.read_csv("healthcare_data.csv" , delimiter=';')  # Replace with your dataset

# Preview data
print(data.head())

# Checking for missing values
print("Missing values before handling:")
print(data.isnull().sum())

print(data['cardio'])

# Check the data type of the target column
print("\nData type of target column:")
print(data['cardio'].dtype)

# If the target is a string or object, convert it to numeric (binary classification: 0 and 1)
data['cardio'] = data['cardio'].astype(int)

# Separate features and target

X = data.drop(columns=['cardio'])  
y = data['cardio']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Logistic Regression Model
log_reg = LogisticRegression(max_iter=1000)
log_reg.fit(X_train, y_train)

# Predictions and Evaluation
y_pred_lr = log_reg.predict(X_test)
y_prob_lr = log_reg.predict_proba(X_test)[:, 1]

# Evaluate AUC-ROC Score
auc_lr = roc_auc_score(y_test, y_prob_lr)
print(f"Logistic Regression AUC-ROC: {auc_lr:.2f}")

# XGBoost Model
xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)
xgb_model.fit(X_train, y_train)

# Predictions and Evaluation
y_pred_xgb = xgb_model.predict(X_test)
y_prob_xgb = xgb_model.predict_proba(X_test)[:, 1]

# Evaluate AUC-ROC Score
auc_xgb = roc_auc_score(y_test, y_prob_xgb)
print(f"XGBoost AUC-ROC: {auc_xgb:.2f}")

# Feature Importance 
xgb_importance = xgb_model.get_booster().get_score(importance_type='weight')
xgb_importance_df = pd.DataFrame(list(xgb_importance.items()), columns=['Feature', 'Importance'])
xgb_importance_df.sort_values(by='Importance', ascending=False, inplace=True)

# Visualize Feature Importance
plt.figure(figsize=(10, 6))
sns.barplot(x='Importance', y='Feature', data=xgb_importance_df)
plt.title("Feature Importance - XGBoost")
plt.show()

# SHAP Values
explainer = shap.Explainer(xgb_model, X_train)
shap_values = explainer(X_test)

# Summary Plot
shap.summary_plot(shap_values, X_test)

# Plot AUC-ROC Curve
fpr_lr, tpr_lr, _ = roc_curve(y_test, y_prob_lr)
fpr_xgb, tpr_xgb, _ = roc_curve(y_test, y_prob_xgb)

plt.figure(figsize=(8, 6))
plt.plot(fpr_lr, tpr_lr, label=f'Logistic Regression (AUC = {auc_lr:.2f})')
plt.plot(fpr_xgb, tpr_xgb, label=f'XGBoost (AUC = {auc_xgb:.2f})')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("AUC-ROC Curve")
plt.legend()
plt.show()

# Prepare Data for Visualization
risk_scores = pd.DataFrame({
    'Patient': X_test.index,
    'Risk Probability': y_prob_xgb,
    'Actual': y_test.values
})

# Interactive Risk Visualization
fig = px.scatter(risk_scores, x='Patient', y='Risk Probability', color='Actual',
                 title="Disease Risk Prediction", labels={"Actual": "Disease Present"})
fig.show()
